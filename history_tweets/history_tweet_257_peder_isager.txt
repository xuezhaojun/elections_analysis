1343989046687707142 2020-12-30 02:35:33 +0800 <peder_isager> @kuszti I wish I could read journal articles that simply identified important unsolved research problems in fields and kept track of progress to solve those problems. Any other effort to organize scientific work within a discipline would also be most welcome!
1343987478278103048 2020-12-30 02:29:19 +0800 <peder_isager> @kuszti Been thinking about this topic alot lately myself. Work on what to replicate is a very small step in what I hope is the right direction. But more important is, I think, for research communities to come together around central research questions and theories in their field.
1343108437207638019 2020-12-27 16:16:19 +0800 <peder_isager> @cjsewall9 @3blue1brown Yes! I should preface, I'm in the final year of the PhD so I can only study... sporadically. But something like a "Psychologists learning calculus" study group would be very useful.
1342937680611520519 2020-12-27 04:57:48 +0800 <peder_isager> @cjsewall9 @3blue1brown Those are next on my list! I'm currently trying to teach myself calculus 13 years too late, and my math background is a shoddy patchwork. If you know anyone other resources you're found helpful, do let me know.
1342749026542899203 2020-12-26 16:28:09 +0800 <peder_isager> Slowly becoming infatuated with @3blue1brown's YouTube channel. His video on epidemic simulation models is such a nice intro for modeling novices (like myself):  https://t.co/UUQdSG6ChL
1336212774523965440 2020-12-08 15:35:25 +0800 <peder_isager> @jargottfried @yudapearl What I don't understand about the airplane example is how the collider "survival" relates to the army's causal effect of interest. Namely "armour location -&gt; survival".
1336212610727993345 2020-12-08 15:34:46 +0800 <peder_isager> @jargottfried Well, normally it is very much possible to relate selection bias to DAG philosophy, because it turns out that selection bias amounts to conditioning on a collider. For the airplane example, @yudapearl explains it like this:   https://t.co/ckYjtT7Ati.
1335236512665964547 2020-12-05 22:56:06 +0800 <peder_isager> @yudapearl Then, forgetting about the collider bias, the army somehow reaches the wrong conclusion about the effect "armor location" -&gt; survival. I could explain to students, in words, what goes wrong here, but I struggle with replacing the verbal explanation with a causal graph.
1335236493217062914 2020-12-05 22:56:02 +0800 <peder_isager> @yudapearl But in this example, the problem seems much more complicated. I.e. the army starts by wanting to know the effect "armor location" -&gt; survival. Somehow, this effect is related to the # of holes ----&gt;survival&lt;----location DAG.
1335236459327000578 2020-12-05 22:55:54 +0800 <peder_isager> @yudapearl Thanks for clarifying! But I still don't understand how the collider relates to the army's initial problem. Normally, the problem with selection bias is simply that we end up believing there is a causal relationship between the independent causes.
1335228739781861382 2020-12-05 22:25:13 +0800 <peder_isager> @bmwiernik @JeanClaudeFox2 @dingding_peng That makes sense! But I still don't understand the causal "story" as well for the airplane example as for the HWE model as examplified in Hern√°n et al. Can you explain what E, C, L, U, and D would correspond to in the airplane example?  https://t.co/jJLNST223S
1335221858057261056 2020-12-05 21:57:52 +0800 <peder_isager> @dingding_peng @bmwiernik  https://t.co/hpAul9YOTV
1335221544684023809 2020-12-05 21:56:38 +0800 <peder_isager> @LeiferJoshua DAG = Directed Acyclic Graph
1335137040892104707 2020-12-05 16:20:50 +0800 <peder_isager> @EpiEllie @fdabl @yudapearl @_MiguelHernan @dingding_peng @psforscher
1335136286932422657 2020-12-05 16:17:51 +0800 <peder_isager> #epitwitter #causaltwitter I am almost certain I've seen Wald's airplane bullet hole case used as an example of selection bias in causal inference, but I cannot for the life of me understand what the DAG corresponding to the example would look like. Any suggestions?  https://t.co/L3Rwhss1ZG
1334184863671480321 2020-12-03 01:17:14 +0800 <peder_isager> @Research_Tim Very happy to hear that Tim. Take care, and hope you find a ton of happy stuff!
1333381484628086786 2020-11-30 20:04:53 +0800 <peder_isager> @alainstarke @WUR @E_VanLoo Best of luck in the new position ^^
1332434518356226049 2020-11-28 05:21:59 +0800 <peder_isager> @faisalmushtaq @PsyArXiv @ugpavlov @annaveer @lakens take a look at the study selection description. The similarities to how we're identifying candidates for our replication are striking! Very interesting to see.
1331965080972505088 2020-11-26 22:16:36 +0800 <peder_isager> @farid_anvari Still one of the most amazing experiences of my life.
1329758377958928388 2020-11-20 20:07:57 +0800 <peder_isager> @annemscheel @drcpennington @dsquintana @lakens @Prof_Larson @farid_anvari Damn, beat me to it
1329758303979786240 2020-11-20 20:07:40 +0800 <peder_isager> @drcpennington @dsquintana @lakens @annemscheel @Prof_Larson You might find @farid_anvari's work on this useful as well. E.g.:  https://t.co/vfxYQLSZWw
1329753094884904960 2020-11-20 19:46:58 +0800 <peder_isager> @mariabloec Brilliant, thanks for the reading tip!
1329725057732665344 2020-11-20 17:55:33 +0800 <peder_isager> Any thoughts @HolgerSteinmetz @dingding_peng @psforscher @fdabl @yudapearl?
1329724641640931331 2020-11-20 17:53:54 +0800 <peder_isager> Is it just me, or is "age" a strange variable to add into a DAG? It has no causes except time passing by, and it feels weird to think of it as a causal parent of something. E.g. it feels strange to say "growing one year older caused me to become 3cm taller".
1329650224374149122 2020-11-20 12:58:11 +0800 <peder_isager> @replicats Any chance the session will be recorded?
1328965796131971074 2020-11-18 15:38:31 +0800 <peder_isager> @HolgerSteinmetz @dwayne_lieck @annemscheel @LeonidTiokhin @lakens Sadly, we had to cut some discussions short due to word limits, but I agree this is an important topic. Ive written a separate preprint elaborating on the relationship between measurement and causality:  https://t.co/73VKFoNWuX, expanding on the ideas of @BorsboomDenny et al.
1328251132305666048 2020-11-16 16:18:42 +0800 <peder_isager> @lakens How about including a COI statement in your comments to the editor? That way, they are at least aware of the potential bias.
1327910290248376322 2020-11-15 17:44:19 +0800 <peder_isager> @farid_anvari @russpoldrack @LisaDeBruine I think you're missing something. @russpoldrack already stated that replicability is not suffient for valid measurement. The question here is wheter replicability is necessary for measurement validity. Can a measure capture the intended construct but never replicate any results?
1318649915472547842 2020-10-21 04:26:53 +0800 <peder_isager> @psforscher Thanks for sharing Patrick. That was very moving. My heart goes out to you.
1317344523350085632 2020-10-17 13:59:44 +0800 <peder_isager> @psforscher @ChrisCrandall16 I think @ChrisCrandall16 is treating papers in the "impossible to substantiate" category as unassignable and recalculates percentages for the remaining set. I am inclined to agree. At least, this type of error seems less severe than the others, and it is also the most frequent.
1314281538809409537 2020-10-09 03:08:31 +0800 <peder_isager> @lakens @giladfeldman @RogertheGS Of course, SPPS might have a completely different utility calculus in mind. Perhaps they're trying to maximize the novelty and impact of the limited number of articles they can afford to process. That's ok I guess. But it is not replication value now - the goal has changed.
1314280879523590152 2020-10-09 03:05:54 +0800 <peder_isager> @lakens @giladfeldman @RogertheGS If your goal is to maximize the amount of money in your pocket and someone offers you free money, it doesn't matter how little money they offer. You should always take whatever they offer, no matter how little it seems to you.
1314280727178027014 2020-10-09 03:05:18 +0800 <peder_isager> @lakens @giladfeldman @RogertheGS Whether SPPS should publish a given replication is neither here nor there to me. But their calculus must be different from what we discuss in our preprint. Otherwise they should accept any conducted replication since, after all, any study that has been conducted is free utility!
1314280535359971331 2020-10-09 03:04:32 +0800 <peder_isager> @lakens @giladfeldman @RogertheGS I did, because it doesn't (if you think RV is about maximizing utility). SPPS cares about the readership appeal of the research topic, period. That, to me, is a completely different goal than thinking "which study would be most useful to replicate in the future".
1311361274270318595 2020-10-01 01:44:26 +0800 <peder_isager> @lpsatchell I really wouldn't mind seeing someone with a real stinger argument tear my definition apart, and I hope someone will feel goaded to write a criticism of it. I am happy as long as, once the dust settles, we will have learned something new and interesting about measurement :)
1311360101316521987 2020-10-01 01:39:46 +0800 <peder_isager> @lpsatchell Hehe, I don't think I've talked to a single person who has been wholly convinced by it yet ;) In fact, I am not completely persuaded myself. I wrote the "notes to sceptics" part to help people turn their intuitive reservations into strong arguments against the definition.
1311221480081022977 2020-09-30 16:28:56 +0800 <peder_isager> @yudapearl @david_disabato @psforscher @BorsboomDenny Thanks for clarifying, and sorry for butchering the description of your nomenclature! I had the "dependence" acronym from a paragraph on this web page:  https://t.co/NJtUtc5AWd.  https://t.co/Dh0jgtBzG1
1311192229260734464 2020-09-30 14:32:42 +0800 <peder_isager> @david_disabato @psforscher @BorsboomDenny @yudapearl This relationship between causality and dependence is what drives the old mantra "correlation does not equal causation".
1311192198399119360 2020-09-30 14:32:35 +0800 <peder_isager> @david_disabato @psforscher @BorsboomDenny @yudapearl Examples of when A and M become statistically dependent: A-&gt;M: when A causes M, they become statistically dependent.  M-&gt;A: When M causes A, , A and M become statistically dependent. A&lt;-U-&gt;M: When M and A are both caused by the same variable, U.
1311192169068277761 2020-09-30 14:32:28 +0800 <peder_isager> @david_disabato @psforscher @BorsboomDenny It's a concept from @yudapearl's causal inference framework. Essentially, variables A and M are d-connected whenever the causal relationship between them makes them statistically dependent ("d" in d-connection means "dependent").
1311023233353814021 2020-09-30 03:21:11 +0800 <peder_isager> @bmwiernik Great, I've updated the preprint as well :)
1311018464438517761 2020-09-30 03:02:14 +0800 <peder_isager> @bmwiernik Would this be better?  https://t.co/sXZsggzikG
1311017040065556481 2020-09-30 02:56:34 +0800 <peder_isager> @bmwiernik Oh boy, really should have thought of this, sorry! I'll update the preprint asap. Will update to blue and orange.
1310907386543177732 2020-09-29 19:40:51 +0800 <peder_isager> Thanks @farid_anvari @dingding_peng @fdabl @_stephanoplis @kaihorstman @jargottfried @turntwine @MetaMethodsPH @lakens and the red^2 journal club for all critical feedback and discussion so far!
1310907385142276106 2020-09-29 19:40:50 +0800 <peder_isager> OBS! I think it is more likely than not that @BorsboomDenny et al. got it right and I wrong, so I will link to any open criticism of my preprint on the suppl. OSF page. If persuaded I am wrong I'll revise my preprint to reflect this, and add the rationale that changed my mind.
1310907382466314246 2020-09-29 19:40:50 +0800 <peder_isager> However, this change would have big consequences. Changing the definition in this way would imply that the following causal models are valid (A-D) and non-valid (E and F). Details and examples in preprint!  https://t.co/Q0MjLwXSmv
1310907377684799494 2020-09-29 19:40:48 +0800 <peder_isager> Essentially, all I am proposing is to change Borsboom et al.'s causal criterion for validity "variations in the attribute causally produce variation in the measurement outcomes‚Äù" to "the target attribute is d-connected to the measured attribute".
1310907375860289538 2020-09-29 19:40:48 +0800 <peder_isager> I propose that, rather than define test validity as "real attribute causes measurement", test validity can be defined as "real attribute is d-connected to measured attribute".  https://t.co/XSRo3Fp9E5
1310907370994896897 2020-09-29 19:40:47 +0800 <peder_isager> I've written a response to @BorsboomDenny et al.'s paper "The Concept of Validity":  https://t.co/mkI6CULnVV. I don't understand what justifies their causal criterion so I propose an alternative definition of test validity that does not include it.  A thread:
1306951143826829312 2020-09-18 21:40:09 +0800 <peder_isager> @chrisdc77 @lakens @RHeirene @giladfeldman ... need to specify the amount of replication the journal commits to? I.e. would it ever be desirable for editors to say "this study is replicated 100 times. We are confident about its replicability and would advice a conceptual RRR instead"?
1306951100415832065 2020-09-18 21:39:58 +0800 <peder_isager> @chrisdc77 @lakens @RHeirene @giladfeldman Actually the pottery barn rule is interesting because it doesn't fit neatly into our model. It makes sense to me for editors to assume "all claims published in our journal are in principle valuable, so a replication of any such claim is worthwhile". But do you think there's any..
1306947433021288454 2020-09-18 21:25:24 +0800 <peder_isager> @giladfeldman @RHeirene I agree that communication is key! The fact that RV only makes sense to consider *before* the replication is conducted is a subtle point, but has huge implications.   I also worry that RV could be misused as a measure of "quality" of original studies, which also makes no sense.
1306946511008399378 2020-09-18 21:21:44 +0800 <peder_isager> @lakens @RHeirene @giladfeldman They can, but imo that would be a nonsensical use of RV as defined by our model. Or at least, the journal cannot have the same goal that our model assumes. They are considering RV after the replication has been conducted, so they cannot be deciding what to replicate.
1306882997388488708 2020-09-18 17:09:21 +0800 <peder_isager> @giladfeldman @RHeirene I am not saying that I would support such restrictive journal policies. But there are definitely journals out there that wants to be restrictive, and those journals would do well to both accept replication studies and to clearly communicate which rep studies they would publish.
1306882538649128961 2020-09-18 17:07:32 +0800 <peder_isager> @giladfeldman @RHeirene But journals could consider e.g. which studies in their own journal are in particular need of replication. Or a journal may offer replication RRs but only it wants to offer IPA to a restricted number of the most valuable submissions.
1306882524086501376 2020-09-18 17:07:29 +0800 <peder_isager> @giladfeldman @RHeirene Important Q. IMO you should NOT use replication value to decide whether to publish a replication study that has been conducted. The resources has already been spent, so it too late to ask if resources are being allocated efficiently.
1306860418208587777 2020-09-18 15:39:38 +0800 <peder_isager> @RHeirene Indeed. At least, we hope our model could make it easier for funders and journals to think about and transparently communicate what kinds of replication proposals they would be most interested in funding and publishing.
1305548673032638466 2020-09-15 00:47:14 +0800 <peder_isager> @SarahHammami3 @GregoryRHancock @DrBlankson @AmandaKMontoya @oscar_olvera100 @TheYiFeng @LauraMStapleton @schotz @SachaEpskamp @EikoFried @wes_bonifay @BD_Zumbo @pdakean @latentchange @dmcneish18 @AndrewJDBell @TeagueRHenry @jarlogan @WillavanDijk @JkayFlake @KMKing_Psych I should also preface that I'm not sure I am a quant psych person. I did my MA in cognitive neuroscience and am currently doing a PhD in meta-science. I like psychology and numbers and I wish I was better at math. Sometimes I get to hang out with @JkayFlake.
1305545963503747072 2020-09-15 00:36:28 +0800 <peder_isager> @SarahHammami3 @GregoryRHancock @DrBlankson @AmandaKMontoya @oscar_olvera100 @TheYiFeng @LauraMStapleton @schotz @SachaEpskamp @EikoFried @wes_bonifay @BD_Zumbo @pdakean @latentchange @dmcneish18 @AndrewJDBell @TeagueRHenry @jarlogan @WillavanDijk @JkayFlake @KMKing_Psych Well, in Norway you have to do an MA before you can apply for a PhD, so I don't really know any other way. Personally I think it was really important for me to do an MA before starting the PhD, but I know very smart people who went straight into the PhD program from their BA.
1305386367757824000 2020-09-14 14:02:17 +0800 <peder_isager> @ctwardy @yangl1u When replicability prediction markets have been compared with survey forecasts in tje past, do you know if those survey takers were rewarded for effort or accuracy?
1305386321343655936 2020-09-14 14:02:06 +0800 <peder_isager> @ctwardy @yangl1u Good point. I guess rewarding accuracy is better for facilitating accurate responding. Problem is that when I want to decide what to replicate, I can't always afford to test the accuracy of the forecasts. I want to generate forecasts that I can assume are accurate.
1305065491447373824 2020-09-13 16:47:14 +0800 <peder_isager> @ctwardy @yangl1u Not to the same extent though, right? With a decision market you have to let the market know what your decision procedure is, since it impact how market gets payed, but with a survey you do not have to reveal to forecasters what you are going to use their predictions for.
1303958859489456129 2020-09-10 15:29:53 +0800 <peder_isager> @yangl1u @ctwardy Never thought about this problem of prediction markets before. What a wonderfully annoying and interesting property!
1303786366778646528 2020-09-10 04:04:27 +0800 <peder_isager> @ctwardy @yangl1u Hm, I think I'm starting to see the problem. You have to somehow pay the market, but if the market knows that you'll only select a subset of claims based on the market forecast, the market will start buying up those claims instead of betting on those most likely to replicate?
1303632619314335749 2020-09-09 17:53:31 +0800 <peder_isager> @ctwardy @yangl1u Immediately, what strikes me is that since it is hard to measure utility gain after replicating, it will be hard to provide a good scoring rule for incentivising accurate market forecasts. I.e. it will be hard to test if markets provide valid forecasts.
1303632601559764992 2020-09-09 17:53:27 +0800 <peder_isager> @ctwardy @yangl1u Reading the paper now but having some trouble translating it to my particular decision problem. Could you elaborate on how you think gaming could arise if markets are used to help decide on what to replicate?
1303027528102182912 2020-09-08 01:49:06 +0800 <peder_isager> Check out our new paper on why exploratory research practices are relevant for hypothesis-testing researchers!  Writing this reminded me of what I love about working in science, and why I love working with @annemscheel @LeonidTiokhin and @lakens.
1303023277183578116 2020-09-08 01:32:12 +0800 <peder_isager> @ctwardy @yangl1u Excellent, thank you!
1302131100622389249 2020-09-05 14:27:01 +0800 <peder_isager> @ctwardy @yangl1u Is that work published and do you have a link? Would love to read.
1302130952945258496 2020-09-05 14:26:26 +0800 <peder_isager> @ctwardy That sounds very interesting! What type of forecasting do you have in mind? Do you mean you will survey researchers for their subjective predictions?
1302129095174696960 2020-09-05 14:19:03 +0800 <peder_isager> @ctwardy @lakens @ReplicationMkts Agree it opens many questions. I suspect an info theory formulation of uncertainty would be an improvement on the model as written. Value is gnarly since it is subjective. But it is clear that we can have intersub agreement, which could form the basis for standardized selection.
1301749047582232576 2020-09-04 13:08:52 +0800 <peder_isager> @cruwelli My condolances Sophia ‚ù§
1301544378276761600 2020-09-03 23:35:35 +0800 <peder_isager> @ctwardy @GivingTools @ReplicationMkts @DARPA @OSFramework Yes ok. So that means the ML algorithm is trying to approximate the result of the replication as closely as possible. I.e. a perfect algorithm would yield 1 bit of info if 100% accurately predicting either "will replicate" or "won't replicate"?
1301541190978985986 2020-09-03 23:22:56 +0800 <peder_isager> @ctwardy If you want examples of possible concrete implementations I would recommend taking a look at the supplementary RV formula documents on OSF:  https://t.co/toi0fc8BhZ
1301226168784433154 2020-09-03 02:31:08 +0800 <peder_isager> @lakens @GivingTools @ctwardy @ReplicationMkts @DARPA @OSFramework @annaveer Indeed, would love to chat!
1301226061641003010 2020-09-03 02:30:43 +0800 <peder_isager> @GivingTools @ctwardy @ReplicationMkts @DARPA @OSFramework Those are exactly the claims most valuable to replicate according to the model we propose. The main barrier to practical implementations is how to measure interest/value and uncertainty reliably. Especially so if ML is going to do the evaluation.
1301202219602243592 2020-09-03 00:55:58 +0800 <peder_isager> @ctwardy @GivingTools @ReplicationMkts @DARPA @OSFramework Very interesting! What criteria do you want the ML algorithm to select for? Should the ML algorithm identify claims/studies that need replication the most? Or is the goal to train the algorithm to identify claims/studies that are already replicable?
1301178249117143040 2020-09-02 23:20:43 +0800 <peder_isager> @ctwardy Main problem is that our model does not currently allow for formally considering the possiblilty that low entropy could be due to error in the person assigning the entropy. Tjis is a valid criticism of our model and definitely something that could be improved on in the future.
1301177124913582082 2020-09-02 23:16:15 +0800 <peder_isager> @TimParker88 Curious to see how the model will be received in different fields. In principle, it could be applied to replication study selection in any empirical science, but the author team are primarily from social science/psych. Feedback from researchers outside that scene is most welcome!
1301171299226656768 2020-09-02 22:53:06 +0800 <peder_isager> @lpsatchell In that case, conceptual rep would probably do more to decrease uncertainty (and increase utility). Ideally we would have a selection methods that could consider both approaches and let us know which is most efficient.
1301171285003771905 2020-09-02 22:53:03 +0800 <peder_isager> @lpsatchell Well, I would classify both reproducibility and validity as being part of assessing "uncertainty" about a claim. The problem is, sometimes a replication will not decrease uncertainty about the claim (e.g. if the study design is not suited to test the claim).
1301169258190249985 2020-09-02 22:45:00 +0800 <peder_isager> @GivingTools @ReplicationMkts Definitely, especially if there are limited resources for replicating and/or evaluating claims. Conversely, replication markets could perhaps be used as a mechanism for identifying claims with high replication value (e.g. replicate that which the market is highly uncertain about)
1301168745176596480 2020-09-02 22:42:58 +0800 <peder_isager> @lpsatchell It would be interesting to consider though - for instance, some research increase utility by reducing uncertainty, but exploratory research could increase utility by identifying valuable research claims.
1301168715598307333 2020-09-02 22:42:51 +0800 <peder_isager> @lpsatchell Thanks. We do briefly suggest that you could extend the utility framework we propose to any kind of study selection decision, though we did not have time to go into detail on this.
1301136071837745152 2020-09-02 20:33:08 +0800 <peder_isager> @Richie_Research @dingding_peng Perhaps not exactly what you're looking for, but we just put up a preprint on replication study selection, in which a DAG is the central model of the paper:  https://t.co/TqezOtCV9C  We don't use it to test hypotheses on data though, which might be what you wanted?
1301135787417833473 2020-09-02 20:32:00 +0800 <peder_isager> @Richie_Research @dingding_peng I've also been looking for more applied examples in psych, but have had no luck yet. Let me know if you come across any good ones!
1301128526649872384 2020-09-02 20:03:09 +0800 <peder_isager> If you‚Äôre more a fan of the video format, the main points of the paper are summarized in this recorded talk I gave for @riotscienceNL:  https://t.co/lLCTHKUlfV
1301128525123067905 2020-09-02 20:03:08 +0800 <peder_isager> Thanks and credit to all my co-authors for all their hard work over the past 8(!) years: Robbie van Aert, @bahniks, @mjbsp, @kadesoto, @RogertheGS, Joachim Krueger, Marco Perugini, @iropovik, @annaveer, @mVranka, and @lakens.
1301128523650945025 2020-09-02 20:03:08 +0800 <peder_isager> Second, that our model can inspire creation of study selection strategies for study selection, so that the resources we have available for replication can be invested in the best possible way.
1301128522228994048 2020-09-02 20:03:08 +0800 <peder_isager> We have two hopes for our model. First, that our model will help researchers to understand and explain why they think some claims should be replicated.
1301128519922200577 2020-09-02 20:03:07 +0800 <peder_isager> Our paper aims to provide this theory. We propose that the goal of replication is to maximize the utility of existing claims, and we explain the decision process that leads us to this goal ‚Ä¶4/  https://t.co/yUzFZfnyu7
1301128518282153984 2020-09-02 20:03:07 +0800 <peder_isager> Researchers have already proposed methods for selecting studies for replication (e.g.  https://t.co/tklI4qZ5GP) by @SMirandaField et al. But there's been no theory to explain what the goal of replication study selection is, and how any proposed method help us reach this goal‚Ä¶ 3/
1301128516784869376 2020-09-02 20:03:06 +0800 <peder_isager> Replication is becoming more commonplace. However, in many fields most studies have never been replicated. Simultaneously, all researchers have limited resources available for replication. I.e. many must choose what to replicate among several options. But how do we do that? ‚Ä¶ 2/
1301128515040018434 2020-09-02 20:03:06 +0800 <peder_isager> New preprint! (my first ever as first author) "Deciding what to replicate: A formal definition of 'replication value'and a decision model for replication study selection.":  https://t.co/DdAtaY75ws   A thread‚Ä¶ 1/
1301030058853904385 2020-09-02 13:31:52 +0800 <peder_isager> Thanks for sharing your story @SchiavoneSays. Its not easy for ECRs to stand up for themselves, which makes it all the more valuable for the rest of us when somebody actually does.
1301025879183831040 2020-09-02 13:15:16 +0800 <peder_isager> @asch3tti @annemscheel I think I could really enjoy a job like that. Who hires research support staff? Universities primarily? Government agencies? Companies?
