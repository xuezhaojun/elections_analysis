1340562142341328898 2020-12-20 15:38:15 +0800 <oseledetsivan> Did the Sputnik-V vaccine today. The mass vaccination in Russia has begun.
1339474488417763328 2020-12-17 15:36:18 +0800 <oseledetsivan> @andrewgwils  https://t.co/gK7vpHVJRz - for upscaling of microstructures, for example. Better than just periodic upscaling.
1336755465716461578 2020-12-10 03:31:53 +0800 <oseledetsivan> @AlexBeatson I think a very close idea is generalized finite element method (see, for example,  https://t.co/iVIYobVZrs? )
1331325137157808133 2020-11-25 03:53:42 +0800 <oseledetsivan> @carlcarrie  https://t.co/WNp56EbRtn - probably relevant  https://t.co/0T3OhQGtuV -- code
1329815526974033928 2020-11-20 23:55:03 +0800 <oseledetsivan> @jakevdp No way that is known to me at least, asked this question some time ago :) There are some inequalities like  https://t.co/1gqvVziYRX but nothing more.
1329755243463270400 2020-11-20 19:55:30 +0800 <oseledetsivan> @matthen2  https://t.co/YiexwpnzRu -- could be relevant :)
1329723189677744128 2020-11-20 17:48:08 +0800 <oseledetsivan> I am really proud of the paper "Adversarial Turing patterns from cellular automata"  https://t.co/YiexwpnzRu We show that universal adversarial examples for CNN proposed by @smoosavid can be generated by Turing patterns with high fooling rates with 2-100 parameters.
1329413184009228289 2020-11-19 21:16:17 +0800 <oseledetsivan> @zhoubolei Does it list the reasons for the rejection?
1328353483427356677 2020-11-16 23:05:24 +0800 <oseledetsivan> @enclanglement And you miss one of the important matrix decompositions - Schur decomposition :)
1328353281844895744 2020-11-16 23:04:36 +0800 <oseledetsivan> @JacobBiamonte @enclanglement  https://t.co/UDJwgTgt8g - that is our poster on the topic :)
1319661267095855104 2020-10-23 23:25:38 +0800 <oseledetsivan> This current paper also listed the Russian government as the funder so we are not able to review it. I hope this information is helpful"   This is pure racism.
1319661265837580290 2020-10-23 23:25:38 +0800 <oseledetsivan> The paper published in 2015 listed the Russian government as the funder, but sanctions have increased since 2015 so now we canâ€™t accept papers funded directly by the Russian government.
1319661264352706560 2020-10-23 23:25:38 +0800 <oseledetsivan> 3/n The three papers published in the last three years list the Russian Science Foundation, which does not currently appear on the sanctions lists. These papers are acceptable for review.
1319661262570213381 2020-10-23 23:25:37 +0800 <oseledetsivan> 2/n "Thank you very much for reaching out. I looked into your previously published work and it looks like you have published four articles in AGU journals since 2015.
1319661261295177728 2020-10-23 23:25:37 +0800 <oseledetsivan> 1/n Recent reply from one of the #AGU #American_Geophysical_Union journals to a paper submitted by Russian scientists (on an innocent topic). Read below - it is pure racism.
1316647363948281858 2020-10-15 15:49:28 +0800 <oseledetsivan> @smoosavid @gortizji @modasapo @pafrossard Yes, indeed. Then it is very interesting!
1316333277553319936 2020-10-14 19:01:24 +0800 <oseledetsivan> @gortizji @modasapo @smoosavid @pafrossard The work of @vforvalya1 :)
1316332650467143680 2020-10-14 18:58:54 +0800 <oseledetsivan> @gortizji @modasapo @smoosavid @pafrossard Nice work! Please note that the definition of NADs eigenvectors (the top one) is the universal adversarial perturbation via singular vector as in  https://t.co/ZJOkOIna0A  https://t.co/2Up3V9E7zZ
1311282359610859521 2020-09-30 20:30:51 +0800 <oseledetsivan> @unsorsodicorda @MichaelPoli6 @NeurIPSConf Yes, you are right - it is a hybrid architecture, and LayerNorm is important. You also correctly described the criterion. If increasing n does not lead to higher accuracy, it is an indicator of "overfitting" to a particular solver.
1310640553520963584 2020-09-29 02:00:33 +0800 <oseledetsivan> @unsorsodicorda @MichaelPoli6 @NeurIPSConf Btw, we have a workshop paper  https://t.co/JhDJ1TZeAH with 93% on CIFAR-10 with NODE and similar accuracy to Resnet-10. The key was layer normalization.
1310131124484608000 2020-09-27 16:16:15 +0800 <oseledetsivan> @Bluengine Thanks! We are still working on the camera-ready version, and we will surely include this reference! :)
1309877785494728707 2020-09-26 23:29:35 +0800 <oseledetsivan> Our paper on speeding up NeuralODE (yes, you do not need to integrate z backwards in time! just interpolate it, and this is stable) got accepted to #NeurIPS2020   https://t.co/frRwNosEti
1307399362360868867 2020-09-20 03:21:12 +0800 <oseledetsivan> @jon_barron @ChrSzegedy Not sure 100%, but 3x3 should reduce to order-3 polynomial rootfinding, which can be reduced to trigonometry (not well-known, but possible).  https://t.co/pFKgXcgQvu So, maybe 3x3 SVD can be found as well.
